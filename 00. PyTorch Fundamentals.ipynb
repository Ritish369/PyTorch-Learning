{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e8896797-64e0-4e05-91a0-f04168f6e7ff",
   "metadata": {},
   "source": [
    "Tensor is the basic and fundamental building block of ML & DL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bd48b128-108e-4237-b42f-5dcd965d17a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.5.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72d49c36-be35-4dcb-98d4-0e210957e972",
   "metadata": {},
   "source": [
    "Tensor's job is to represent data in a numerical way."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60263722-10e4-45c0-a226-c0a216976c00",
   "metadata": {},
   "source": [
    "### Creating Tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe2575be-61d3-4d15-8603-223c1d2165b7",
   "metadata": {},
   "source": [
    "Using torch.empty() with the dtype argument is the recommended way of creating tensors as mentioned in PyTorch docs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97c860ae-e008-453e-9148-22614041d643",
   "metadata": {},
   "source": [
    "**torch.Tensor class**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3bf6cb8b-d779-44f8-bcdc-0022a4aad732",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A Scaler is a zero dimension tensor i.e., a single number.\n",
    "scaler = torch.tensor(3)\n",
    "scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "472e49b6-f907-4b1a-b868-fec24ddbd00a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dimensions check\n",
    "scaler.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "69acaf5a-8ae7-4398-9965-47de9e16a967",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To access the number within the 0-dim tensor\n",
    "scaler.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4c46bf60-28b8-49be-8e6b-f6e81caa3dd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3., 3.])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A Vector is a single dimension tensor with many nums.\n",
    "vector = torch.Tensor([3, 3])\n",
    "vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "79d41f09-1870-402f-8e89-72f063aea5e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dimensions (A quick way is to count the square brackets on the outside of one side for dims.)\n",
    "vector.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0890fcec-8819-43a3-b6d4-3aed82d90cc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The shape attribute tells how the elements inside tensors are arranged.\n",
    "vector.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4d9c3fcb-1d37-49a0-944a-2dc91de0bbb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2],\n",
       "        [3, 4]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Matrix has an extra dim and is as flexible as vectors.\n",
    "MATRIX = torch.tensor([[1, 2],\n",
    "                       [3, 4]])\n",
    "MATRIX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "52fdb7a4-7a05-4721-88b5-6bcfd1cc44ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MATRIX.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7865a07a-a30c-4493-a3a8-3eafce329885",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MATRIX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e7141964-a1b1-4619-b320-007ed9ac34b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1., 2., 3.],\n",
       "         [4., 5., 6.],\n",
       "         [7., 8., 9.]]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tensor (n-dimnal array of numbers)\n",
    "TENSOR = torch.Tensor([[[1, 2, 3],\n",
    "                        [4, 5, 6],\n",
    "                        [7, 8, 9]]])\n",
    "TENSOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "25e10676-ef63-4390-a0bc-ad307b338535",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TENSOR.ndim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbae7f61-f4ae-4e48-9c7a-2355b4adf0a8",
   "metadata": {},
   "source": [
    "Dimensions go outer to inner i.e., TENSOR has 1 dimension of 3 x 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2a3f9b0b-9e73-4dd7-9448-a4047d5fb73d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 3])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TENSOR.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0f5c242-0e00-4321-a0f0-a964a9baa4c7",
   "metadata": {},
   "source": [
    "Scalers & Vectors are in lowercase letters while Matrices & Tensors are in Uppercase letters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83407e4c-eb8d-4f22-bec6-31cbf2b8e262",
   "metadata": {},
   "source": [
    "Even though the names matrix & tensor are used interchangeably, which is common, the shape and dimensions of what's inside will dictate what it actually is."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d970e22-dd8c-4db0-b3e5-01553a046113",
   "metadata": {},
   "source": [
    "A 0-dim tensor is a scaler and a 1-dim tensor is a vector."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9db9ed6c-327b-4958-8045-c539a29f2a18",
   "metadata": {},
   "source": [
    "### Random Tensors"
   ]
  },
  {
   "cell_type": "raw",
   "id": "07ce8a7f-aaad-41ac-a5f9-1ff9935f6302",
   "metadata": {},
   "source": [
    "In essence, an ML model does the following with the numbers in tensors:\n",
    "Start with random numbers -> look at data -> update random numbers -> look at data -> update random numbers...\n",
    "\n",
    "It can be defined how ML model starts (initialization), looks at data (representation) and updates (optimization) its random numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b54b914e-7509-4644-9e31-9a3992331aa0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.7973, 0.0797, 0.3333, 0.2791],\n",
       "         [0.8921, 0.4333, 0.1706, 0.1832],\n",
       "         [0.9034, 0.8427, 0.8575, 0.4944]]),\n",
       " torch.float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a random tensor of size parameter\n",
    "random_tensor = torch.rand(size=(3, 4))\n",
    "random_tensor, random_tensor.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e12d74ee-d26b-4372-941e-97f88153886d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([224, 224, 3]), 3)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_image_size_tensor = torch.rand(size=(224, 224, 3))\n",
    "random_image_size_tensor.shape, random_image_size_tensor.ndim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c371adc2-513a-4e34-a46f-ce25f67d952c",
   "metadata": {},
   "source": [
    "### Zeros and Ones (Used a lot for masking)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a0f93305-bfdd-4e87-8464-b3e9d94d98ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.]]),\n",
       " torch.float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A tensor of all zeros\n",
    "zeros = torch.zeros(size = (3, 4))\n",
    "zeros, zeros.dtype\n",
    "\n",
    "# A tensor of all ones.\n",
    "ones = torch.ones(size = (3, 4))\n",
    "ones, ones.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25b45756-701a-4cca-8cb9-8db98d4a048e",
   "metadata": {},
   "source": [
    "### Creating a range and tensors like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "411f8903-d492-46fc-aa30-b2072ade3679",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Range of values from 0 to 10\n",
    "zero_to_ten = torch.arange(start=0, end=10, step=1) # torch.range(start, end) is deprecated.\n",
    "zero_to_ten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "69503afd-30e5-4b58-88eb-57fa4f303cff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.zeros_like(input) and torch.ones_like(input)\n",
    "ten_zeros = torch.zeros_like(input = zero_to_ten)\n",
    "ten_zeros\n",
    "\n",
    "ten_ones = torch.ones_like(input = zero_to_ten)\n",
    "ten_ones"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "397f67d3-d7ca-4b5e-b238-16921ce31581",
   "metadata": {},
   "source": [
    "### Tensor datatypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d071cad2-bb6e-4093-8133-5853b41521de",
   "metadata": {},
   "source": [
    "Tensors from torch.cuda seen anywhere means they are being used for GPU. Generally, torch.float32 is the default data type."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "799d76e4-f4d8-4cf6-8f44-16577f2dd9b2",
   "metadata": {},
   "source": [
    "All this mess around Tensor datatypes has a reason to do with **precision in computing.**\n",
    "\n",
    "Precision is the amount of detail used to describe a number. This leads to a trade off between faster computation & performance on evaluation metrics."
   ]
  },
  {
   "cell_type": "raw",
   "id": "a3df74ad-81aa-429a-834e-f29c1f9fd1da",
   "metadata": {},
   "source": [
    "This matters in DL and numerical computing, a lot."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b989937b-6c48-4a51-ac9c-2ea2649c4dc0",
   "metadata": {},
   "source": [
    "dtype parameter is used to create a tensor of some specific datatype."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b85cde01-0c56-4068-9a48-0a52dd131049",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3]), torch.float32, device(type='cpu'))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float_32_tensor = torch.tensor([3.0, 6.0, 9.0], dtype = None, device = None, requires_grad = False)\n",
    "# requires_grad allows to record operations performed on the tensor, if True.\n",
    "\n",
    "float_32_tensor.shape, float_32_tensor.dtype, float_32_tensor.device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba3a20d9-021d-4181-b9ae-7d1673ce1051",
   "metadata": {},
   "source": [
    "Aside from shape mismatch issues, datatype and device issues are the other most common issues inn PyTorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "292465bc-65f1-4b55-872f-e9d760d59df7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float16"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float_16_tensor = torch.tensor([3.0, 6.0, 9.0], dtype = torch.float16)\n",
    "float_16_tensor.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cc97022f-edfb-4231-a126-7254ab8f0905",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4628, 0.7803, 0.8970, 0.2979],\n",
      "        [0.3584, 0.9926, 0.5619, 0.2524],\n",
      "        [0.5067, 0.8404, 0.0892, 0.9977]])\n",
      "torch.Size([3, 4])\n",
      "torch.float32\n",
      "cpu\n"
     ]
    }
   ],
   "source": [
    "# GETTING INFORMATION FROM TENSORS\n",
    "\n",
    "some_tensor = torch.rand(3, 4)\n",
    "\n",
    "# Details about the tensor are as follows: (3 attributes are shape, type and device)\n",
    "print(some_tensor)\n",
    "print(some_tensor.shape)\n",
    "print(some_tensor.dtype)\n",
    "print(some_tensor.device)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0a949174-198a-47bc-a18a-fbcf203de8d0",
   "metadata": {},
   "source": [
    "Note: Whenever issues arise in PyTorch, it is very often to do with one of the above three attributes. So, checkout with them on issues coming up. {WHAT, WHAT and WHERE.}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fd062e9-139e-4d51-a2d9-95b5fb51b060",
   "metadata": {},
   "source": [
    "### Manipulating Tensors (tensor operations)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9fa06eb-9470-4f41-8206-997d30339d71",
   "metadata": {},
   "source": [
    "Addition, Subtraction, Multiplication (element-wise), Division and Matrix Multiplication -- Basic building blocks of NNs.\n",
    "\n",
    "The most sophisticated of NNs can be created by stacking these building blocks in the right way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "96b5caa5-e60a-4603-90bb-a9b2b8657860",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(14)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor = torch.tensor([1, 2, 3])\n",
    "tensor + 10\n",
    "tensor * 10\n",
    "tensor\n",
    "\n",
    "tensor = tensor - 10\n",
    "tensor\n",
    "tensor = tensor + 10\n",
    "tensor\n",
    "\n",
    "# Some built-in functions for these ops: torch.mul(), torch.add()\n",
    "torch.multiply(tensor, 10)\n",
    "tensor\n",
    "\n",
    "# element-wise multiplication\n",
    "tensor * tensor\n",
    "\n",
    "# Matrix Multiplication (denoted by @ in Python) -- One of the most common ops in ML & DL algos.\n",
    "# Two rules to follow: 1) Inner dimensions must match. 2) Resulting matrix has the shape of the outer dimensions\n",
    "tensor.shape\n",
    "\n",
    "# The difference between matmul and element-wise mul is the addition of values.\n",
    "tensor * tensor\n",
    "torch.matmul(tensor, tensor)\n",
    "tensor @ tensor # Not recommended to use"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52837c49-cbdd-4f7f-9179-448619d1ad4c",
   "metadata": {},
   "source": [
    "Avoid doing operations with for loop at all cost as they are computationally expensive."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b31b9ead-09eb-40b6-afe6-b731a27522d8",
   "metadata": {},
   "source": [
    "**One of the most common errors in DL is shape mismatches.** However, this can be prevented by making the tensors' inner dimensions match. \n",
    "\n",
    "One of the ways to do so is to take the **transpose**.\n",
    "\n",
    "Ways to do so are: torch.transpose(input, dim0, dim1) or tensor.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cfa1b8d6-7b54-4be3-b571-198110069de0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2.],\n",
      "        [3., 4.],\n",
      "        [5., 6.]])\n",
      "tensor([[1., 3., 5.],\n",
      "        [2., 4., 6.]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 5., 11., 17.],\n",
       "        [11., 25., 39.],\n",
       "        [17., 39., 61.]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_A = torch.tensor([[1, 2],\n",
    "                         [3, 4],\n",
    "                         [5, 6]], dtype = torch.float32)\n",
    "print(tensor_A)\n",
    "print(tensor_A.T)\n",
    "\n",
    "# torch.mm can also be used for matmul -- short for torch.matmul()\n",
    "torch.mm(tensor_A, tensor_A.T)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "56f9deeb-2b9d-46a1-92a1-550aef006d11",
   "metadata": {},
   "source": [
    "The matrix multiplication as done above is also referred to as the Dot product of two matrices."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "447dbcf3-8739-4489-aef9-bac2799b373c",
   "metadata": {},
   "source": [
    "NNs are full of matrix muls. and dot products."
   ]
  },
  {
   "cell_type": "raw",
   "id": "ef2de122-9d22-4dc5-941e-34843b2fb707",
   "metadata": {},
   "source": [
    "At last, it is all Matrix Multiplication (& all one needs.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e6e3be1-f923-431e-a0f6-cfc1c77b836d",
   "metadata": {},
   "source": [
    "### Aggregation operartions on Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bc6747e0-3cea-4c8a-a439-6b9c1aa4619b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0, 10, 20, 30, 40, 50, 60, 70, 80, 90])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.arange(0, 100, 10)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9ed32e09-165b-4448-bfe6-236f6088da4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0)\n",
      "tensor(90)\n",
      "tensor(45.)\n",
      "tensor(450)\n",
      "90, 0, 45.0, 450\n",
      "9, 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor(9), tensor(0))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(x.min())\n",
    "print(x.max())\n",
    "print(x.type(torch.float32).mean()) # x.mean() will give error thus, won't work.\n",
    "print(x.sum())\n",
    "\n",
    "# Same above ops can be done using torch\n",
    "print(f\"{torch.max(x)}, {torch.min(x)}, {torch.mean(x.type(torch.float32))}, {torch.sum(x)}\")\n",
    "\n",
    "# torch.mean() or mean over tensors require tensors to be in specific datatype, otherwise the operation will fail.\n",
    "\n",
    "# Positional min, max (index of min, max)\n",
    "print(f\"{x.argmax()}, {x.argmin()}\")\n",
    "torch.argmax(x), torch.argmin(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "069221a8-6381-486a-80da-04af3082c0a7",
   "metadata": {},
   "source": [
    "### Change tensor datatype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f872107-cd7e-479d-a880-ed057000bff8",
   "metadata": {},
   "source": [
    "The datatypes can be changed using **torch.Tensor.type(dtype=None)** where the dtype parameter is the datatype one would like to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5dbd8c5c-2766-4a71-85f6-c97eaf66aabf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor = torch.arange(10., 100., 10.)\n",
    "tensor.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8b992fdc-df68-4588-9947-7038f4743994",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([10., 20., 30., 40., 50., 60., 70., 80., 90.], dtype=torch.float16)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_float16 = tensor.type(torch.float16)\n",
    "tensor_float16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cca6ca46-aa3d-463f-b64c-42083389a479",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([10, 20, 30, 40, 50, 60, 70, 80, 90], dtype=torch.int8)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_int8 = tensor.type(torch.int8)\n",
    "tensor_int8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc3ca70d-0ae9-4d3c-9dcf-fc54e0c718d3",
   "metadata": {},
   "source": [
    "### Reshaping, stacking, sqeezing and unsqueezing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a54efc3-f684-4e9e-ab1d-ac8e26f5b7bf",
   "metadata": {},
   "source": [
    "Used to avoid shape mismatch errors and allows to be compliant with the tensor manipulations done in DL models i.e., NNs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0a4abfdc-2095-4a80-a4ec-d2de9b3046bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1., 2., 3., 4., 5., 6., 7.]), torch.Size([7]))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.arange(1., 8.)\n",
    "x, x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2a80a059-2828-434a-9ba5-74177077762d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1., 2., 3., 4., 5., 6., 7.]]), torch.Size([1, 7]))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add extra dimension\n",
    "x_reshaped = x.reshape(1, 7)\n",
    "x_reshaped, x_reshaped.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6b603930-7041-4a1d-9bdd-47f0be2c4943",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2., 3., 4., 5., 6., 7.]]), torch.Size([1, 7])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([[5., 2., 3., 4., 5., 6., 7.]]), tensor([5., 2., 3., 4., 5., 6., 7.]))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Change view of the original tensor into a different size tensor with the data kept intact\n",
    "# This creates a new view of the same tensor.\n",
    "z = x.view(1, 7)\n",
    "print(f\"{z}, {z.shape}\")\n",
    "\n",
    "# Changing the view changes the original tensor too i.e., changing z changes x\n",
    "z[:, 0] = 5\n",
    "z, x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c1e9803a-f809-41dc-8f00-06b8bc4fb854",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[5., 2., 3., 4., 5., 6., 7.],\n",
       "        [5., 2., 3., 4., 5., 6., 7.],\n",
       "        [5., 2., 3., 4., 5., 6., 7.],\n",
       "        [5., 2., 3., 4., 5., 6., 7.]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Stack tensors on top of each other\n",
    "x_stacked = torch.stack([x, x, x, x], dim = 0) # dim value just means along rows(0) or along cols(1).\n",
    "x_stacked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "65592705-7da3-4ab8-ab0b-0daa4b006e11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[5., 2., 3., 4., 5., 6., 7.]]), torch.Size([1, 7])\n",
      "tensor([5., 2., 3., 4., 5., 6., 7.]), torch.Size([7])\n",
      "tensor([[5., 2., 3., 4., 5., 6., 7.]]), torch.Size([1, 7])\n"
     ]
    }
   ],
   "source": [
    "# Removing all single dimensions from a tensor -- squeezing the tensor (torch.squeeze()).\n",
    "print(f\"{x_reshaped}, {x_reshaped.shape}\")\n",
    "\n",
    "x_squeezed = x_reshaped.squeeze()\n",
    "print(f\"{x_squeezed}, {x_squeezed.shape}\")\n",
    "\n",
    "# To reverse the effect of squeezing -- use torch.unsqueeze()\n",
    "x_unsqueezed = x_squeezed.unsqueeze(dim = 0)\n",
    "print(f\"{x_unsqueezed}, {x_unsqueezed.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "685339ff-294f-44a3-bbc7-713d069db7bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "orig shape: torch.Size([224, 224, 3]), permuted/new shape: torch.Size([3, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "# To rearrange the order of axes values, where the iput gets turned into a view with new dims\n",
    "# Use torch.permute(input, dims)\n",
    "x_original = torch.rand(size = (224, 224, 3))\n",
    "\n",
    "# Permuting the orig tensor to rearrange the axis order\n",
    "x_permuted = x_original.permute(2, 0, 1) # It is like transposing using the dims value of the axes\n",
    "\n",
    "print(f\"orig shape: {x_original.shape}, permuted/new shape: {x_permuted.shape}\")\n",
    "# However, changes in view (as given by .permute) will apply to the original as well as stated above but the values remains unchanged unless explicitly changed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40701c1e-3733-4b44-b3dd-e06883f3ef98",
   "metadata": {},
   "source": [
    "### Indexing (selecting data from tensors) -- akin to accessing of values in list or arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "086d0bb1-0bc1-4cde-94df-ee83edef5ba3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[1, 2, 3],\n",
      "         [4, 5, 6],\n",
      "         [7, 8, 9]]]), torch.Size([1, 3, 3])\n",
      "tensor([[1, 2, 3],\n",
      "        [4, 5, 6],\n",
      "        [7, 8, 9]])\n",
      "tensor([1, 2, 3])\n",
      "tensor(1)\n",
      "\n",
      "\n",
      "tensor([[1, 2, 3]])\n",
      "tensor([[2, 5, 8]])\n",
      "tensor([5])\n",
      "tensor([1, 2, 3])\n"
     ]
    }
   ],
   "source": [
    "x = torch.arange(1, 10).reshape(1, 3, 3)\n",
    "print(f\"{x}, {x.shape}\")\n",
    "\n",
    "# Indexing values goes from outer dim to inner dim -- indexing done as follows, bracket by bracket:\n",
    "print(x[0])\n",
    "print(x[0][0])\n",
    "print(x[0][0][0])\n",
    "print(\"\\n\")\n",
    "\n",
    "# Alternatives -- using : to specify all vals in this dimension and using a comma(,)\n",
    "print(f\"{x[:, 0]}\")\n",
    "print(f\"{x[:, :, 1]}\")\n",
    "print(f\"{x[:, 1, 1]}\")\n",
    "print(f\"{x[0, 0, :]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c57190ae-6efc-4761-9505-f45ade55f3ac",
   "metadata": {},
   "source": [
    "### PyTorch tensors & NumPy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dae25ccc-6758-40fd-b281-6ffec957788b",
   "metadata": {},
   "source": [
    "Mainly deals with conversion from NumPy arrays to PyTorch tensors and vice-versa."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9db1d510-bfa9-4168-bc33-e9339db8734d",
   "metadata": {},
   "source": [
    "Two main methods for this are:\n",
    "\n",
    "torch.from_numpy(ndarray) & torch.Tensor.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8ea43c79-bbd1-45a3-a813-143b8d0436af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 2. 3. 4. 5. 6. 7.], tensor([1., 2., 3., 4., 5., 6., 7.], dtype=torch.float64)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([2., 3., 4., 5., 6., 7., 8.]),\n",
       " tensor([1., 2., 3., 4., 5., 6., 7.], dtype=torch.float64))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# NumPy array to PyTorch tensor\n",
    "import numpy as np\n",
    "array = np.arange(1.0, 8.0)\n",
    "tensor = torch.from_numpy(array)\n",
    "print(f\"{array}, {tensor}\")\n",
    "array = array + 1\n",
    "array, tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "873c69ff-fde2-4185-9d44-8a1de6ec6930",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([2., 2., 2., 2., 2., 2., 2.]),\n",
       " array([1., 1., 1., 1., 1., 1., 1.], dtype=float32))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# PyTorch tensor to NumPy array\n",
    "tensor = torch.ones(7)\n",
    "numpy_tensor = tensor.numpy()\n",
    "tensor, numpy_tensor\n",
    "tensor = tensor + 1\n",
    "tensor, numpy_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de2bcae1-2dc7-44b2-8f73-79b642b2f7a1",
   "metadata": {},
   "source": [
    "One thing to note that changing the original array/tensor doesn't change the corresponding converted tensor/array."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8c2d60f-9aa2-42f9-a494-4c451d2befac",
   "metadata": {},
   "source": [
    "### Reproducibility"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63f953e4-2319-4053-af46-f7b2e566430a",
   "metadata": {},
   "source": [
    "NNs in short: \n",
    "start with random numbers -> tensor operations -> try to make better (again and again and again)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "73a7ec3d-96b0-4e35-a444-dac54d439d40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.6852, 0.2281, 0.8645, 0.3337],\n",
      "        [0.3616, 0.5672, 0.7066, 0.9459],\n",
      "        [0.7997, 0.0789, 0.9352, 0.8612]])\n",
      "tensor([[0.1847, 0.1068, 0.8875, 0.9612],\n",
      "        [0.6770, 0.9360, 0.8160, 0.4056],\n",
      "        [0.8611, 0.7475, 0.5178, 0.4935]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[False, False, False, False],\n",
       "        [False, False, False, False],\n",
       "        [False, False, False, False]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating 2 random tensors\n",
    "random_tensor_A = torch.rand(3, 4)\n",
    "random_tensor_B = torch.rand(3, 4)\n",
    "\n",
    "print(f\"{random_tensor_A}\")\n",
    "print(f\"{random_tensor_B}\")\n",
    "# Equality Check\n",
    "random_tensor_A == random_tensor_B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7c4cbefb-ae08-4342-a04a-a95ce549655a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.8823, 0.9150, 0.3829, 0.9593],\n",
      "        [0.3904, 0.6009, 0.2566, 0.7936],\n",
      "        [0.9408, 0.1332, 0.9346, 0.5936]])\n",
      "tensor([[0.8823, 0.9150, 0.3829, 0.9593],\n",
      "        [0.3904, 0.6009, 0.2566, 0.7936],\n",
      "        [0.9408, 0.1332, 0.9346, 0.5936]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[True, True, True, True],\n",
       "        [True, True, True, True],\n",
       "        [True, True, True, True]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What if wanted to create random tensors again but with the same flavour? But still have random values.\n",
    "# Here comes torch.manual_seed(seed) comes in.\n",
    "\n",
    "import random\n",
    "RANDOM_SEED = 42\n",
    "torch.manual_seed(seed = RANDOM_SEED)\n",
    "random_tensor_C = torch.rand(3, 4)\n",
    "\n",
    "# Need to reset the seed everytime a new rand() is called. Otherwise, different unflavoured tensors.\n",
    "torch.random.manual_seed(seed = RANDOM_SEED)\n",
    "random_tensor_D = torch.rand(3, 4)\n",
    "\n",
    "print(f\"{random_tensor_C}\")\n",
    "print(f\"{random_tensor_D}\")\n",
    "# Equality Check\n",
    "random_tensor_C == random_tensor_D"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d25a8dc5-36ac-4453-98ec-cd2e8b8a3679",
   "metadata": {},
   "source": [
    "Reproducibility and randomness (determinism and all) are important to know in DL."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "933b1bbd-cb32-4916-8bec-32860615326f",
   "metadata": {},
   "source": [
    "### Running tensors on GPUs (for faster computations)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dbc086b-de51-4d8e-9428-653888cb93c2",
   "metadata": {},
   "source": [
    "GPUs are much faster than CPU at performing the specific types of operatioons NNs need (matmuls)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0a6afc0-7654-459e-b0e3-fca53d62cda3",
   "metadata": {},
   "source": [
    "Once the GPU is being detected, the next step is to get PyTorch to run on the GPU i.e., for storing data (tensors) & computing on data (performing operations on tensors)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f283914-8b8a-4cfd-82ac-268100ff326a",
   "metadata": {},
   "source": [
    "**torch.cuda package** is employed to do so."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e116546f-8e9e-482f-93ed-4c72151dc538",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To check if pytorch has access to the GPU\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "78a2322e-9c9b-4b07-9536-279739409a43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set device type depending on whatever is available\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "raw",
   "id": "820e93b5-f3a1-4cae-9dc0-d1bcd97758db",
   "metadata": {},
   "source": [
    "In PyTorch, it is best practice to write **device-agnostic code**. It means that the code will run on CPU (default) or GPU (if available)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "51555c4a-acc7-48c8-9838-c44c7ae83ac9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count number of devices PyTorch has access to.\n",
    "torch.cuda.device_count() # Useful when need to use multiple GPUs in cases of wanting even faster computations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd761641-b82f-454c-a38a-ee92388f5514",
   "metadata": {},
   "source": [
    "#### Putting tensors (& models) on the GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0032d245-6728-4b7a-9235-2595a99cd92e",
   "metadata": {},
   "source": [
    "Done by calling **to(device)** on the tensor (or model) that is to be put on GPU, where device is the target device."
   ]
  },
  {
   "cell_type": "raw",
   "id": "16d1bcd5-f1f4-4fb9-a0cc-def8f2a7f799",
   "metadata": {},
   "source": [
    "Note: Putting a tensor on GPU using to(device) (e.g. some_tensor.to(device)) returns a copy of that tensor, e.g. the same tensor will be on CPU and GPU. To overwrite tensors, reassign them:\n",
    "\n",
    "some_tensor = some_tensor.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c44453f6-1da3-4dae-99e3-15db3b442d60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3]) cpu\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3], device='cuda:0')"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tensor default on CPU\n",
    "tensor = torch.tensor([1, 2, 3])\n",
    "\n",
    "# Tensor not on GPU\n",
    "print(tensor, tensor.device)\n",
    "\n",
    "# Move tensor to GPU (if available)\n",
    "tensor_on_gpu = tensor.to(device)\n",
    "tensor_on_gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e27b1a6b-cf3d-4ce4-8e83-6223e80020ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Moving tensors back to the CPU -- .cpu() is used to do so.\n",
    "tensor_back_on_cpu = tensor_on_gpu.cpu().numpy() # This copies the orig tensor on GPU to the CPU memory to be uable with CPUs.\n",
    "tensor_back_on_cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2741c734-51ac-4d2e-b37f-ab7eb2ca4f7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3], device='cuda:0')"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_on_gpu # However, the orig tensor is still on the GPU."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5acd14fe-c937-450c-b9a2-f4fb17f518e5",
   "metadata": {},
   "source": [
    "## Exercises"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5a1334eb-7e2a-4c3b-9b0f-2078be1fae24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.8694, 0.5677, 0.7411, 0.4294, 0.8854, 0.5739, 0.2666],\n",
       "        [0.6274, 0.2696, 0.4414, 0.2969, 0.8317, 0.1053, 0.2695],\n",
       "        [0.3588, 0.1994, 0.5472, 0.0062, 0.9516, 0.0753, 0.8860],\n",
       "        [0.5832, 0.3376, 0.8090, 0.5779, 0.9040, 0.5547, 0.3423],\n",
       "        [0.6343, 0.3644, 0.7104, 0.9464, 0.7890, 0.2814, 0.7886],\n",
       "        [0.5895, 0.7539, 0.1952, 0.0050, 0.3068, 0.1165, 0.9103],\n",
       "        [0.6440, 0.7071, 0.6581, 0.4913, 0.8913, 0.1447, 0.5315]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rt = torch.rand(size=(7,7))\n",
    "rt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "23cc4214-1f8c-4399-adad-7730dd4468f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1587, 0.6542, 0.3278, 0.6532, 0.3958, 0.9147, 0.2036]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[1.9625],\n",
       "        [1.0950],\n",
       "        [0.9967],\n",
       "        [1.8910],\n",
       "        [1.9205],\n",
       "        [1.0674],\n",
       "        [1.6949]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rt2 = torch.rand(size=(1,7))\n",
    "print(rt2)\n",
    "rslt = torch.matmul(rt, rt2.T)\n",
    "rslt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3ab9ffdb-2f39-4c44-9651-42eec17f3637",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4963, 0.7682, 0.0885, 0.1320, 0.3074, 0.6341, 0.4901],\n",
      "        [0.8964, 0.4556, 0.6323, 0.3489, 0.4017, 0.0223, 0.1689],\n",
      "        [0.2939, 0.5185, 0.6977, 0.8000, 0.1610, 0.2823, 0.6816],\n",
      "        [0.9152, 0.3971, 0.8742, 0.4194, 0.5529, 0.9527, 0.0362],\n",
      "        [0.1852, 0.3734, 0.3051, 0.9320, 0.1759, 0.2698, 0.1507],\n",
      "        [0.0317, 0.2081, 0.9298, 0.7231, 0.7423, 0.5263, 0.2437],\n",
      "        [0.5846, 0.0332, 0.1387, 0.2422, 0.8155, 0.7932, 0.2783]])\n",
      "tensor([[0.4820, 0.8198, 0.9971, 0.6984, 0.5675, 0.8352, 0.2056]])\n",
      "tensor([[1.8542],\n",
      "        [1.9611],\n",
      "        [2.2884],\n",
      "        [3.0481],\n",
      "        [1.7067],\n",
      "        [2.5290],\n",
      "        [1.7989]])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "rt = torch.rand(size=(7,7))\n",
    "print(rt)\n",
    "rt2 = torch.rand(size=(1,7))\n",
    "print(rt2)\n",
    "rslt_seed = torch.matmul(rt, rt2.T)\n",
    "print(rslt_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ba361d59-1ab4-462c-a5b3-1c361612ec4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.manual_seed(1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "337af3fc-7bf0-4027-af99-751057aabf62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "tensor([[0.0290, 0.4019, 0.2598],\n",
      "        [0.3666, 0.0583, 0.7006]], device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0.0518, 0.4681, 0.6738],\n",
       "        [0.3315, 0.7837, 0.5631]], device='cuda:0')"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(1234)\n",
    "\n",
    "print(torch.cuda.is_available())\n",
    "\n",
    "rt = torch.rand(size=(2,3))\n",
    "rt_gpu = rt.to(device)\n",
    "print(rt_gpu)\n",
    "\n",
    "rt2 = torch.rand(size=(2,3))\n",
    "rt_gpu2 = rt2.to(device)\n",
    "rt_gpu2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "055988da-edda-405a-bc10-f2ad036dce3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.3647, 0.4709],\n",
       "        [0.5184, 0.5617]], device='cuda:0')"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rslt_gpu = torch.matmul(rt_gpu, rt_gpu2.T)\n",
    "rslt_gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "702ea84f-d04e-4eb8-b61d-f99fb8d4491c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.5617, device='cuda:0'), tensor(0.3647, device='cuda:0'))"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.max(rslt_gpu), torch.min(rslt_gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "9c13bcf0-11fd-4457-acf4-26c72ecd6544",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(3, device='cuda:0'), tensor(0, device='cuda:0'))"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.argmax(rslt_gpu), torch.argmin(rslt_gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "1f3619e8-5944-49a8-8fb3-67be7062cddb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[0.5349, 0.1988, 0.6592, 0.6569, 0.2328, 0.4251, 0.2071, 0.6297,\n",
      "           0.3653, 0.8513]]]]) torch.Size([1, 1, 1, 10])\n",
      "tensor([0.5349, 0.1988, 0.6592, 0.6569, 0.2328, 0.4251, 0.2071, 0.6297, 0.3653,\n",
      "        0.8513]) torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(7)\n",
    "\n",
    "rand_tensor = torch.rand(size=(1, 1, 1, 10))\n",
    "print(rand_tensor, rand_tensor.shape)\n",
    "\n",
    "rand_tensor_squeezed = rand_tensor.squeeze()\n",
    "print(rand_tensor_squeezed, rand_tensor_squeezed.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1599110f-ae43-42d7-b466-587951750748",
   "metadata": {},
   "source": [
    "**In-place operations are denoted by an _ suffix.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4a76017-84da-4fab-8a5d-34f633be960d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (pytorch-env)",
   "language": "python",
   "name": "pytorch-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
